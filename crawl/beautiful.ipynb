{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup\n",
    "- 파서(html, xml 의 형태로 내려온 데이터를 원하는 요소만 찾기 위해 필요)\n",
    "- requests + bs4 : 이 조합으로 주로 크롤링\n",
    "- 파서 종류\n",
    "    - html.parser (두번째 속도)\n",
    "    - lxml (속도가 가장 빠름) : 설치가 필요 pip install lxml\n",
    "    - html5lib (가장 느림)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>[속보] '음주 뺑소니' 김호중, 구속영장 심사 위해 법원 출석</title>\n",
      "<h3 class=\"tit_view\" data-translation=\"true\">[속보] '음주 뺑소니' 김호중, 구속영장 심사 위해 법원 출석</h3>\n",
      "[속보] '음주 뺑소니' 김호중, 구속영장 심사 위해 법원 출석\n",
      "{'class': ['tit_view'], 'data-translation': 'true'}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://v.daum.net/v/20240524110601445\"\n",
    "\n",
    "with requests.Session() as s:\n",
    "    r = s.get(url)\n",
    "    # print(r.text)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\") # 파서 종류 선택해서 사용\n",
    "    # print(soup)\n",
    "\n",
    "    # 요소 접근\n",
    "    # 태그명 사용\n",
    "    print(soup.title)\n",
    "    print(soup.h3)\n",
    "    # 태그의 text 추출\n",
    "    print(soup.title.get_text())\n",
    "    # attrs : 태그 속성 추출\n",
    "    print(soup.h3.attrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : <title>The Dormouse's story</title>\n",
      "title content : The Dormouse's story\n",
      "title content : The Dormouse's story\n",
      "title parent : <head>\n",
      "<title>The Dormouse's story</title>\n",
      "</head>\n",
      "============================================================\n",
      "p : <p class=\"title\">\n",
      "<b> The Dormouse's story </b>\n",
      "</p>\n",
      "p : The Dormouse's story\n",
      "p : {'class': ['title']}\n",
      "p : ['title']\n",
      "============================================================\n",
      "b : <b> The Dormouse's story </b>\n",
      "b : The Dormouse's story\n"
     ]
    }
   ],
   "source": [
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\") as f:\n",
    "    r = f.read()\n",
    "    # print(r.text)\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "    # print(soup)\n",
    "\n",
    "    # title 태그 가져오기\n",
    "    title = soup.title\n",
    "    print(f\"title : {title}\")\n",
    "    print(f\"title content : {title.get_text()}\")\n",
    "    print(f\"title content : {title.string}\")\n",
    "    print(f\"title parent : {title.parent}\")\n",
    "    print(\"==\" * 30)\n",
    "    # p 태그 가져오기\n",
    "    p1 = soup.p\n",
    "    print(f\"p : {p1}\")\n",
    "    print(f\"p : {p1.get_text().strip()}\") # text 부를때는 공백제거\n",
    "    print(f\"p : {p1.attrs}\")\n",
    "    print(f\"p : {p1[\"class\"]}\")\n",
    "    print(\"==\" * 30)\n",
    "    # b 태그 가져오기\n",
    "    b1 = soup.b\n",
    "    print(f\"b : {b1}\")\n",
    "    print(f\"b : {b1.string.strip()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p2 : <p class=\"story\">\n",
      "      Once upon a time there were three little sisters; and their names were\n",
      "      <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> Elsie </a>\n",
      "      ,\n",
      "      <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"> Lacie </a>\n",
      "      and\n",
      "      <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"> Tillie </a>\n",
      "      ; and they lived at the bottom of a well.\n",
      "    </p>\n",
      "p2 : Once upon a time there were three little sisters; and their names were\n",
      "       Elsie \n",
      "      ,\n",
      "       Lacie \n",
      "      and\n",
      "       Tillie \n",
      "      ; and they lived at the bottom of a well.\n",
      "p2 : {'class': ['story']}\n",
      "p2 : ['story']\n"
     ]
    }
   ],
   "source": [
    "# 문서의 구조를 이용한 요소 찾기\n",
    "# parent, children, next_sibling....\n",
    "\n",
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\") as f:\n",
    "    r = f.read()\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "\n",
    "    # body = soup.body\n",
    "    # print(f\"body children : {body.children}\")\n",
    "    # for child in body.children:\n",
    "    #     print(child)\n",
    "\n",
    "    # 첫번째 p 요소 찾기\n",
    "    p1 = soup.p\n",
    "    p2 = p1.find_next_sibling(\"p\")\n",
    "    print(f\"p2 : {p2}\")\n",
    "    print(f\"p2 : {p2.get_text().strip()}\")\n",
    "    # print(f\"p2 : {p2.string.strip()}\") # AttributeError: 'NoneType' object has no attribute 'strip'\n",
    "    print(f\"p2 : {p2.attrs}\")\n",
    "    print(f\"p2 : {p2[\"class\"]}\")\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<title>The Dormouse's story</title>\n",
      "</head>\n",
      "================================================================================\n",
      "<p class=\"title\">\n",
      "<b> The Dormouse's story </b>\n",
      "</p>\n",
      "================================================================================\n",
      "<p class=\"story\">\n",
      "      Once upon a time there were three little sisters; and their names were\n",
      "      <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> Elsie </a>\n",
      "      ,\n",
      "      <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"> Lacie </a>\n",
      "      and\n",
      "      <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"> Tillie </a>\n",
      "      ; and they lived at the bottom of a well.\n",
      "    </p>\n",
      "================================================================================\n",
      "<p class=\"story\">...</p>\n",
      "================================================================================\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> Elsie </a>\n",
      "================================================================================\n",
      "http://example.com/tillie\n",
      "================================================================================\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> Elsie </a>\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"> Lacie </a>\n"
     ]
    }
   ],
   "source": [
    "# find() : 조건을 만족하는 요소 하나 찾기\n",
    "# find_all() : 조건을 만족하는 요소 모두 찾기\n",
    "\n",
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\") as f:\n",
    "    r = f.read()\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "\n",
    "    head = soup.find(\"head\")\n",
    "    print(head)\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # p1 = soup.find(\"p\")\n",
    "    # print(p1)\n",
    "    p1 = soup.find(\"p\", attrs={\"class\":\"title\"})\n",
    "    print(p1)\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # p2 = soup.find(\"p\", attrs={\"class\":\"story\"})\n",
    "    p2 = soup.find(\"p\", class_=\"story\")\n",
    "    print(p2)\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    p_all = soup.find_all(\"p\", class_=\"story\")\n",
    "    # print(p_all)\n",
    "    print(p_all[1])\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # a1 = soup.find(\"a\", attrs={\"id\":\"link1\"})\n",
    "    a1 = soup.find(\"a\", id=\"link1\")\n",
    "    print(a1)\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    a3 = soup.find(\"a\", id=\"link3\")\n",
    "    print(a3[\"href\"])\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    a_tags = soup.find_all(\"a\", limit=2)\n",
    "    for ele in a_tags:\n",
    "        print(ele)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elsie', 'Lacie', 'Tillie']\n",
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n"
     ]
    }
   ],
   "source": [
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\") as f:\n",
    "    r = f.read()\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "\n",
    "    # link1 = soup.find_all(string=\"Elsie\")\n",
    "    link1 = soup.find_all(string=[\"Elsie\",\"Lacie\",\"Tillie\"])\n",
    "    link2 = soup.find_all(\"a\", string=[\"Elsie\",\"Lacie\",\"Tillie\"])\n",
    "    print(link1)\n",
    "    print(link2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna\n",
      "Pavlovna SchererEmpress Marya\n",
      "FedorovnaPrince Vasili KuraginAnna PavlovnaSt. Petersburgthe princeAnna PavlovnaAnna Pavlovnathe princethe princethe princePrince VasiliAnna PavlovnaAnna Pavlovnathe princeWintzingerodeKing of Prussiale Vicomte de MortemartMontmorencysRohansAbbe Moriothe Emperorthe princePrince VasiliDowager Empress Marya Fedorovnathe baronAnna Pavlovnathe Empressthe EmpressAnna Pavlovna'sHer MajestyBaron\n",
      "FunkeThe princeAnna\n",
      "Pavlovnathe EmpressThe princeAnatolethe princeThe princeAnna\n",
      "PavlovnaAnna PavlovnaWell, Prince, so Genoa and Lucca are now just family estates of the\n",
      "Buonapartes. But I warn you, if you don't tell me that this means war,\n",
      "if you still try to defend the infamies and horrors perpetrated by\n",
      "that Antichrist- I really believe he is Antichrist- I will have\n",
      "nothing more to do with you and you are no longer my friend, no longer\n",
      "my 'faithful slave,' as you call yourself! But how do you do? I see\n",
      "I have frightened you- sit down and tell me all the news.\n",
      "If you have nothing better to do, Count [or Prince], and if the\n",
      "prospect of spending an evening with a poor invalid is not too\n",
      "terrible, I shall be very charmed to see you tonight between 7 and 10-\n",
      "Annette Scherer.\n",
      "Heavens! what a virulent attack!\n",
      "First of all, dear friend, tell me how you are. Set your friend's\n",
      "mind at rest,\n",
      "Can one be well while suffering morally? Can one be calm in times\n",
      "like these if one has any feeling?\n",
      "You are\n",
      "staying the whole evening, I hope?\n",
      "And the fete at the English ambassador's? Today is Wednesday. I\n",
      "must put in an appearance there,\n",
      "My daughter is\n",
      "coming for me to take me there.\n",
      "I thought today's fete had been canceled. I confess all these\n",
      "festivities and fireworks are becoming wearisome.\n",
      "If they had known that you wished it, the entertainment would\n",
      "have been put off,\n",
      "Don't tease! Well, and what has been decided about Novosiltsev's\n",
      "dispatch? You know everything.\n",
      "What can one say about it?\n",
      "What has been decided? They have decided that\n",
      "Buonaparte has burnt his boats, and I believe that we are ready to\n",
      "burn ours.\n",
      "Oh, don't speak to me of Austria. Perhaps I don't understand\n",
      "things, but Austria never has wished, and does not wish, for war.\n",
      "She is betraying us! Russia alone must save Europe. Our gracious\n",
      "sovereign recognizes his high vocation and will be true to it. That is\n",
      "the one thing I have faith in! Our good and wonderful sovereign has to\n",
      "perform the noblest role on earth, and he is so virtuous and noble\n",
      "that God will not forsake him. He will fulfill his vocation and\n",
      "crush the hydra of revolution, which has become more terrible than\n",
      "ever in the person of this murderer and villain! We alone must\n",
      "avenge the blood of the just one.... Whom, I ask you, can we rely\n",
      "on?... England with her commercial spirit will not and cannot\n",
      "understand the Emperor Alexander's loftiness of soul. She has\n",
      "refused to evacuate Malta. She wanted to find, and still seeks, some\n",
      "secret motive in our actions. What answer did Novosiltsev get? None.\n",
      "The English have not understood and cannot understand the\n",
      "self-abnegation of our Emperor who wants nothing for himself, but only\n",
      "desires the good of mankind. And what have they promised? Nothing! And\n",
      "what little they have promised they will not perform! Prussia has\n",
      "always declared that Buonaparte is invincible, and that all Europe\n",
      "is powerless before him.... And I don't believe a word that Hardenburg\n",
      "says, or Haugwitz either. This famous Prussian neutrality is just a\n",
      "trap. I have faith only in God and the lofty destiny of our adored\n",
      "monarch. He will save Europe!\n",
      "I think,\n",
      "None\n",
      "In a moment. A propos,\n",
      "None\n",
      "I shall be delighted to meet them,\n",
      "But tell me,\n",
      "is it true that the Dowager Empress wants Baron Funke\n",
      "to be appointed first secretary at Vienna? The baron by all accounts\n",
      "is a poor creature.\n",
      "Baron Funke has been recommended to the Dowager Empress by her\n",
      "sister,\n",
      "Now about your family. Do you know that since your daughter came\n",
      "out everyone has been enraptured by her? They say she is amazingly\n",
      "beautiful.\n",
      "I often think,\n",
      "None\n",
      "Two such charming children. And really you appreciate\n",
      "them less than anyone, and so you don't deserve to have them.\n",
      "I can't help it,\n",
      "Lavater would have said I\n",
      "lack the bump of paternity.\n",
      "Don't joke; I mean to have a serious talk with you. Do you know I\n",
      "am dissatisfied with your younger son? Between ourselves\n",
      "he was mentioned at Her\n",
      "Majesty's and you were pitied....\n",
      "What would you have me do?\n",
      "You know I did all\n",
      "a father could for their education, and they have both turned out\n",
      "fools. Hippolyte is at least a quiet fool, but Anatole is an active\n",
      "one. That is the only difference between them.\n",
      "And why are children born to such men as you? If you were not a\n",
      "father there would be nothing I could reproach you with,\n",
      "I am your faithful slave and to you alone I can confess that my\n",
      "children are the bane of my life. It is the cross I have to bear. That\n",
      "is how I explain it to myself. It can't be helped!\n"
     ]
    }
   ],
   "source": [
    "url = \"https://pythonscraping.com/pages/warandpeace.html\"\n",
    "\n",
    "with requests.Session() as s:\n",
    "    r = s.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "# 등장인물 출력\n",
    "actors = soup.find_all(\"span\", class_=\"green\")\n",
    "for actor in actors:\n",
    "    print(actor.string, end=\"\")\n",
    "# 대사 출력\n",
    "dialoues = soup.find_all(\"span\", class_=\"red\")\n",
    "for d in dialoues:\n",
    "    print(d.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목 : [속보] '음주 뺑소니' 김호중, 구속영장 심사 위해 법원 출석\n",
      "작성자 : 이종원\n",
      "작성 날짜, 시간 : 2024. 5. 24. 11:06\n",
      "첫번째 문단 : '음주 뺑소니' 김호중, 구속영장 심사 위해 법원 출석 \n",
      "'음주 뺑소니' 김호중, 구속영장 심사 위해 법원 출석 \n",
      "김호중 \"진심으로 죄송…법원 심문 잘 받겠다\" \n",
      "소속사 대표·본부장 등 구속영장 심사도 함께 진행 \n",
      "김호중 등 구속 여부 오늘 안에 결론 전망 \n",
      "검찰 \"사안 중대하고 증거인멸 우려 커 검사 직접 출석\" \n",
      "김호중, 위험운전치상·범인도피방조 등 4개 혐의 적용 \n",
      "경찰, 김호중 만취 정황 포착…직접 증거인멸도 의심 \n",
      "사고 낸 뒤 매니저와 옷 갈아입고 '바꿔치기' \n",
      "사고 차량 등에선 블랙박스 메모리 카드 훼손 \n",
      "◇ 자세한 뉴스가 이어집니다. \n",
      "YTN 이종원 (jongwon@ytn.co.kr)\n",
      "※ '당신의 제보가 뉴스가 됩니다' \n",
      "[카카오톡] YTN 검색해 채널 추가 \n",
      "[전화] 02-398-8585 \n",
      "[메일] social@ytn.co.kr\n",
      "[저작권자(c) YTN 무단전재, 재배포 및 AI 데이터 활용 금지]\n"
     ]
    }
   ],
   "source": [
    "url = \"https://v.daum.net/v/20240524110601445\"\n",
    "\n",
    "with requests.Session() as s:\n",
    "    r = s.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    # 뉴스 제목\n",
    "    title = soup.find(\"h3\", class_=\"tit_view\")\n",
    "    print(f\"제목 : {title.string}\")\n",
    "    # 작성자\n",
    "    writer = soup.find(\"span\", class_=\"txt_info\")\n",
    "    print(f\"작성자 : {writer.string}\")\n",
    "    # 작성시간\n",
    "    time = soup.find(\"span\", class_=\"num_date\")\n",
    "    print(f\"작성 날짜, 시간 : {time.string}\")\n",
    "    # 첫번째 문단 가져오기\n",
    "    para = soup.find(\"p\", attrs={\"dmcf-ptype\":\"general\"})\n",
    "    print(f\"첫번째 문단 : {para.text}\")\n",
    "    # 전체 본문 내용 가져오기\n",
    "    paras = soup.find_all(\"p\", attrs={\"dmcf-ptype\":\"general\"})\n",
    "    for p in paras:\n",
    "        print(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b> The Dormouse's story </b>\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n"
     ]
    }
   ],
   "source": [
    "# css select 사용\n",
    "# select() : 전체요소 / select_one()\n",
    "\n",
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\") as f:\n",
    "    r = f.read()\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "\n",
    "    title = soup.select_one(\"p.title > b\")\n",
    "    print(title)\n",
    "\n",
    "    link1 = soup.select_one(\"#link1\")\n",
    "    print(link1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
      "Elsie\n",
      "Elsie\n",
      "Elsie\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "Lacie\n",
      "Lacie\n",
      "Lacie\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "Tillie\n",
      "Tillie\n",
      "Tillie\n"
     ]
    }
   ],
   "source": [
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\") as f:\n",
    "    r = f.read()\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "\n",
    "    stories = soup.select(\"p.story > a\") # 리스트로 반환\n",
    "    # print(stories)\n",
    "\n",
    "    for story in stories:\n",
    "        print(story)\n",
    "        print(story.text)\n",
    "        print(story.string)\n",
    "        print(story.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
      "==== Elsie\n",
      "==== <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      "==== Lacie\n",
      "==== <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      "==== Tillie\n",
      "===>  <p class=\"story\">...</p>\n",
      "===>  ...\n"
     ]
    }
   ],
   "source": [
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\") as f:\n",
    "    r = f.read()\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "\n",
    "    stories = soup.select(\"p.story\")\n",
    "    # print(stories)\n",
    "\n",
    "    for story in stories:\n",
    "        temp = story.find_all(\"a\")\n",
    "        \n",
    "        if temp:\n",
    "            for v in temp:\n",
    "                print(\"====\", v)\n",
    "                print(\"====\", v.string)\n",
    "        else:\n",
    "                print(\"===> \", story)\n",
    "                print(\"===> \", story.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목 : [속보] '음주 뺑소니' 김호중, 구속영장 심사 위해 법원 출석\n",
      "작성자 : 이종원\n",
      "작성 날짜, 시간 : 2024. 5. 24. 11:06\n",
      "첫번째 문단 : '음주 뺑소니' 김호중, 구속영장 심사 위해 법원 출석 \n",
      "'음주 뺑소니' 김호중, 구속영장 심사 위해 법원 출석 \n",
      "김호중 \"진심으로 죄송…법원 심문 잘 받겠다\" \n",
      "소속사 대표·본부장 등 구속영장 심사도 함께 진행 \n",
      "김호중 등 구속 여부 오늘 안에 결론 전망 \n",
      "검찰 \"사안 중대하고 증거인멸 우려 커 검사 직접 출석\" \n",
      "김호중, 위험운전치상·범인도피방조 등 4개 혐의 적용 \n",
      "경찰, 김호중 만취 정황 포착…직접 증거인멸도 의심 \n",
      "사고 낸 뒤 매니저와 옷 갈아입고 '바꿔치기' \n",
      "사고 차량 등에선 블랙박스 메모리 카드 훼손 \n",
      "◇ 자세한 뉴스가 이어집니다. \n",
      "YTN 이종원 (jongwon@ytn.co.kr)\n",
      "※ '당신의 제보가 뉴스가 됩니다' \n",
      "[카카오톡] YTN 검색해 채널 추가 \n",
      "[전화] 02-398-8585 \n",
      "[메일] social@ytn.co.kr\n",
      "[저작권자(c) YTN 무단전재, 재배포 및 AI 데이터 활용 금지]\n"
     ]
    }
   ],
   "source": [
    "# select(), select_one() 으로 변경\n",
    "url = \"https://v.daum.net/v/20240524110601445\"\n",
    "\n",
    "with requests.Session() as s:\n",
    "    r = s.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    # 뉴스 제목\n",
    "    title = soup.select_one(\"h3\")\n",
    "    print(f\"제목 : {title.string}\")\n",
    "\n",
    "    # # 작성자\n",
    "    writer = soup.select_one(\"span\")\n",
    "    print(f\"작성자 : {writer.string}\")\n",
    "\n",
    "    # # 작성시간\n",
    "    time = soup.select_one(\"span > span.num_date\")\n",
    "    print(f\"작성 날짜, 시간 : {time.string}\")\n",
    "\n",
    "    # # 첫번째 문단 가져오기\n",
    "    para = soup.select_one(\"p[dmcf-ptype='general']\")\n",
    "    print(f\"첫번째 문단 : {para.text}\")\n",
    "\n",
    "    # # 전체 본문 내용 가져오기\n",
    "    paras = soup.select(\"p[dmcf-ptype='general']\")\n",
    "    for p in paras:\n",
    "        print(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML>\n",
      "<html lang=\"ko\">\n",
      "<head>\n",
      "    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"/>\n",
      "    <meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=1.0,minimum-scale=1.0,user-scalable=no\">\n",
      "    <meta name=\"description\" lang=\"ko\" content=\"잠시 후 다시 확인해주세요! : 네이버쇼핑\">\n",
      "    <title>에러 페이지 : 네이버쇼핑</title>\n",
      "    <link rel=\"stylesheet\" type=\"text/css\" href=\"//img.pay.naver.net/static/css/customer/naver_error.css\">\n",
      "\n",
      "    <script src=\"https://ssl.pstatic.net/static/fe/grafolio.js\"></script>\n",
      "</head>\n",
      "\n",
      "\n",
      "<body>\n",
      "<div id=\"u_skip\" class=\"u_skip\">\n",
      "    <a href=\"#content\">본문 바로가기</a>\n",
      "</div>\n",
      "<div class=\"wrap\">\n",
      "    <div class=\"header\" role=\"banner\">\n",
      "        <h1 class=\"logo\"><a href=\"//naver.com\" class=\"logo_link\"><img src=\"//img.pay.naver.net/static/images/customer/naver_logo.png\" width=\"90\" height=\"16\"\n",
      "                                                                             alt=\"네이버\"></a></h1>\n",
      "        <div class=\"nav\" role=\"navigation\">\n",
      "            <a href=\"//naver.com\" class=\"nav_link\">네이버홈</a>\n",
      "            <a href=\"//help.pay.naver.com\" class=\"nav_link\">쇼핑&페이 고객센터</a>\n",
      "        </div>\n",
      "    </div>\n",
      "    <hr>\n",
      "    <div class=\"container\" role=\"main\">\n",
      "        <div class=\"content\" id=\"content\">\n",
      "            <div class=\"image_area _errorImage\"></div>\n",
      "\n",
      "            <div class=\"info_area\">\n",
      "                <div class=\"info_txt\">\n",
      "                    <strong class=\"tit\">잠시 후 다시 확인해주세요!</strong>\n",
      "                    <p class=\"txt\">\n",
      "                        지금 이 서비스와 연결할 수 없습니다.<br>\n",
      "                        문제를 해결하기 위해 열심히 노력하고 있습니다.<br>\n",
      "                        잠시 후 다시 확인해주세요.\n",
      "                    </p>\n",
      "                </div>\n",
      "                <div class=\"info_link\">\n",
      "                    <a href=\"javascript:history.go(-1)\" class=\"link_prev\">이전 페이지</a><a href=\"//shopping.naver.com\" class=\"link_home\">네이버쇼핑 홈</a>\n",
      "                </div>\n",
      "            </div>\n",
      "        </div>\n",
      "    </div>\n",
      "    <hr>\n",
      "    <div class=\"footer\" role=\"contentinfo\">\n",
      "        <address>\n",
      "            <span>Copyright</span> ©<a href=\"http://www.navercorp.com\" class=\"link_naver\" target=\"_blank\">NAVER Corp.</a> <span>All Rights Reserved.</span>\n",
      "        </address>\n",
      "    </div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fake_useragent import UserAgent\n",
    "\n",
    "url = \"https://finance.naver.com/\"\n",
    "\n",
    "userAgent = UserAgent()\n",
    "\n",
    "headers = {\"user-agent\": userAgent.chrome}\n",
    "\n",
    "with requests.Session() as s:\n",
    "    r = s.get(url, headers=headers)\n",
    "    print(r.text)\n",
    "    # soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
